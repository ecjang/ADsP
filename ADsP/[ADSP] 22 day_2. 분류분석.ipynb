{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Chapter05. 정형 데이터 마이닝</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>제 2절. 분류 분석</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류하고자 하는 타켓값을 범주형으로 설정하고, 입력변수를 이용해 **타켓을 분류예측하는 패턴을 파악하는 방법**이다.\n",
    "- 정의된 유한한 범주로 분류하는 분석하는 방법\n",
    "- 잘 정의된 범주와 충분한 훈련 데이터를 확보하는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRM : 갬페인에 반응할 고객과 그렇치 않을 고객 분류\n",
    "- 금융기관 : 고객의 대출한도액 분류, 우량 및 불량 고객 분류\n",
    "- 주식 : 상승 및 하락 예상 종목 분류, 부실기업 예측\n",
    "- 다수의 범주형 변수의 병합을 통한 범주 축소\n",
    "- 연속현 변수의 이산화 작업\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 적용시 유의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 정의된 Training 데이터를 확보하여 **[Training 훈련]과 [Validation 검증]**을 위해 8:2 또는 7:3으로 나누어야 하고, 개발 모델을 검증할 Test 데이터도 확보해야 한다. \n",
    "- 동일 기간내의 검증용 데이터는 물론, 인접한 다른 기간의 데이터로 변동 기간에도 안정적으로 작용하는지 검증해야 함\n",
    "- 예: 1~6월까지의 데이터가 있다면 1~4월 데이터를 훈련용과 검증용으로 나누어 검증한 후, 5,6월 데이터로 다시 한 번 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **[Decision Tree 의사 결정 나무] : tree**\n",
    "1. **[Logistic Regression 로지스틱 회귀분석]**\n",
    "1. **[Nearest Neighborhood 최근접 이웃] : kknn**\n",
    "1. **[Neural Network 신경망 분석] : nnet**\n",
    "1. **[Support Vector Machine 지지도벡터기계] : e1071**\n",
    "1. **[Classification And Regression Tree CARET] : caret**\n",
    "1. **[Baysian Theorem 베이시안 정리] : LearnBayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4_2. [Logistic Regression 로지스틱 회귀분석]\n",
    "\n",
    "특정 집단에 속할 추정확률을 **[Posterior Probability 사후확률]**이라고 하며, 변수별 **[Odds 오즈]**값을 이용해 해당 값이 증가할 때 예측값이 얼마나 증가하는지를 알려주기 때문에 주로 사용하는 분석 방법이다. \n",
    "- 표준 로지스틱 분포의 누적확률분포로 1을 예측\n",
    "- 유사한 Probit 모형은 표준정규분포의 누적확률함수로 모형화한 것. 기준값이 0.5보다 크면 1로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 의사결정 나무\n",
    "\n",
    "의사 결정 규칙이 나무 모형으로 이루어진 분류 방법이다.\n",
    "\n",
    "- 결정 시점과 성과를 한 눈에 볼 수 있음\n",
    "- 계산 결과가 직접 나타나 분석이 간편함\n",
    "- 계산이 복잡하지 않아 대용량데이터에도 적합\n",
    "- 비정상 잡음 데이터에도 민감함 없이 분류 가능\n",
    "- 상관성이 높은 다른 변수가 있어도 크게 영향을 받지 않음\n",
    "\n",
    "#### 의사결정나무 용어\n",
    "- [Node 노드] : 각 분기점\n",
    "- [Root Node 뿌리노드] : 최상위 분기점\n",
    "- [Ternimal Node 끝노드] : 자식이 없는 마디\n",
    "- [Leaf 잎] : 최하단의 각 개체가 속하는 그룹, 분류의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris 의사결정 예제\n",
    "- iris : http://localhost:8888/notebooks/%5Bdata%5D%20DecisionTree_Iris.ipynb\n",
    "- wine : http://localhost:8888/notebooks/%5Bdata%5D%20DecisionTree_Wine.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 신경망 분석\n",
    "\n",
    "뇌의 처리구조를 모방한 인공신경망 기법으로 입력된 값을 분류하거나 연속형 값을 예측하는데 사용한다. \n",
    "- 입력한 값에 따라 **[Wegith 가중치]**가 부여되고 **[Activation Function 활성화 함수]**에 따라 출력값이 결정됨\n",
    "- 원하는 값이 나올 때까지 오차가 작아지게 가중치가 조정\n",
    "- 입력 출력 모두 한개 또는 여러개 가능\n",
    "- **[Hidden Layer 은닉층]** 입력층과 출력층 사이에 있는 층으로 입력과 출력사이에서 가중치 계산\n",
    "- IT발전으로 처리속도가 빨라지고, GPU 다수의 코어로 빠른 연산이 가능해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iris 분석 : http://localhost:8888/notebooks/%5Bdata%5D%20NNet_Iris.ipynb\n",
    "- infert 분석 : http://localhost:8888/notebooks/%5Bdata%5D%20NeuralNet_infert.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [Enssemble 앙상블]\n",
    "\n",
    "한 개의 데이텅 대해 여러개의 모델을 [Conbine 합치거나], 또는 [Consensus 만장일치]에 의해 예측값을 결정하는 방법이다. 마치 여러분야의 전문가들의 의견을 모아 하나로 합치는 방식과 유사하며 예측성능을 높일 수 있는 장점이 있지만 이해가 어려운 단점이 있다.\n",
    "- 각각의 알고리즘 마다 장점이 다르기 때문에 여러 모델의 결과를 결합하여 사용\n",
    "- Netflix 경진대회에서 각 팀의 예측을 결합한 방식이 우승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7_1. [Bagging Bootstrap Aggregation 배깅]\n",
    "\n",
    "전체 데이터에서 **동일 크기로 단순 복원 추출한 데이터**로 모델을 생성하고 결합하는 방식이다.\n",
    "- **[Bootstrap 부트스트랩]** : 동일 크기로 단순복원추출한 데이터\n",
    "- adabag 패키지를 사용, 앙상블 모델을 이용하려면 caet 패키지를 사용\n",
    "\n",
    "\n",
    "- iris Bagging 분석 : http://localhost:8888/notebooks/%5Bdata%5D%20EnssembleBagging_Iris.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7_2. [Boosting 부스팅]\n",
    "\n",
    "Bagging과 비슷한 방식에 **오분류된 데이터에 가중치**를 주어서 추출하는 방식이다. adaBoosting 방법이 많이 사용된다.\n",
    "- 편향이나 분산을 줄여서 성과를 내는 방식\n",
    "- 다른 모델에서 변수 중요도가 낮은 변수의 중요도가 높게 나옴\n",
    "\n",
    "\n",
    "- iris Boosting 분석 : http://localhost:8888/notebooks/%5Bdata%5D%20EnssembleBoosting_Iris.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7_3. [Random Forest 랜덤 포레스트]\n",
    "\n",
    "가치치기할 때 Tree 구성을 시도하며 **상관관계를 줄이는데** 이 과정으로 오류가 줄어들기 때문에 **Bagging 보다 성능이 좋다.** 앙상블 분석에서 선호하는 방법이다.\n",
    "\n",
    "- 분류에서는 **Majority Voting**을 사용, 회귀분석에서는 예측의 평균을 이용\n",
    "- 별도의 검증 데이터가 없어도 [OOB Out og Bag] 과정에서 제외된 자료를 이용해 검증\n",
    "- [Impurity 불순도]의 감소가 얼마나 나타나는지로 변수의 중요도를 제공\n",
    "- Gini Index를 이용해 노드의 불순도를 측정\n",
    "- 회귀모형의 경우 최소자승법으로 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8_1. [Confusion Matrix 혼돈 행렬]\n",
    "\n",
    "도출한 결과와 실제 값을 비교한 테이블로 **정확성 지표**를 정확히 알 수 있다.\n",
    "\n",
    "- WayToLiah : https://www.waytoliah.com/1222\n",
    "- Data School : https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오분류표\n",
    "\n",
    "1. **[Accuracy 정확도]** : (TP+TN)/Total, 올바르게 검출 (실제 악성/정상을 예측)\n",
    "1. **[Misclassification Rate=Error Rate 오류율]** : (FP+FN)/Total, 잘못되게 검출 (잘못된 악성/정상 예측)\n",
    "1. **[Precision 정밀도]** : TP/Predicted YES, 참으로 분류한 것중 올바른 참의 비율 (악성으로 예측한 것 중 실제 악성 샘플의 비율)\n",
    "1. **[Recall, Detection Rate 재현율, 검출율]** : TP/Actual YES, 실제 참을 참으로 분류 (실제 악성 중에서 악성으로 예측)\n",
    "1. **[False Alarm 오검출율, 오경보률]** : FP/Actual NO, 실제 거짓을 거짓으로 분류 (실제 정상 중에서 악성으로 예측 )\n",
    "1. **[TPR True Positive Rate=Recall, Sencitivity 적중확률, 민감도]** : TP/Actual YES, 예측과 실제 모두 참 (실제 악성 중에서 악성으로 예측)\n",
    "1. **[TNR True Negative Tate=Sepecificity 특이도]** : TN/Actual NO, 예측과 실제 모두 거짓 (실제 정상 중에서 정상으로 예측)\n",
    "1. **[FPR False Positive Rate=False Alarm]** : FP/Actual NO, 실제 거짓인데 참으로 분류 (실제 정상을 악성으로 예측)\n",
    "1. **[FNR False Negative Rate]** : FN/Acutual YES, 실제 참인데 거짓으로 검출 (실제 악성을 정상으로 예측)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall\n",
    "\n",
    "다크 프로그래머 : http://darkpgmr.tistory.com/162\n",
    "\n",
    "검출률만으로 모델을 평가하는 것은 의미가 없다. 원하는 목표를 높은 확률로 분류하지만 오검출이 높은 모델과 검출률이 낮지만 오검출이 거의 없는 모델 중 어느 것이 더 좋은 모델인지 평가하기 어렵다. 즉 모델읜 성능을 평가할 때는 **[Precision 정밀도]**과 **[Detection Rate, Recall 검출률, 재현율]**를 동시에 고려해야 한다. 일반적으로 검출률과 정확도는 서로 반비례 관계이다.\n",
    "\n",
    "\n",
    "- **[Precision 정밀도]**\n",
    "    - 분류된 결과가 **얼마나 정확한지**에 대한 척도. 분류 결과중 실제 결과가 얼마나 포함되어 있는지를 나타냄\n",
    "    $$ Precision = \\frac{Detected \\ TRUE(TP)}{Predicted \\ YES} $$\n",
    "\n",
    "\n",
    "- **[Recall, Detection Rate 재현율, 검출률]**\n",
    "    - 데이터셋에서 원하는 목표를 **얼마나 잘 분류하는지**에 대한 척도, 분류 결과를 나타냄\n",
    "    $$ Precision = \\frac{Predicted \\ TRUE}{Actual \\ Yes} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Accuracy \n",
    "\n",
    "성제훈의 우리말 : https://goo.gl/258Xzn\n",
    "\n",
    "두 단어는 동일한 의미의 단어임에도 문맥에 따라 의미가 달라질 수 있다. 의미로 보면 **[Precision 정밀도], [Accuracy 정확도]**이며 어떤 시스템의 성능을 평가하는 척도로 사용한다.\n",
    "\n",
    "- **[Accuracy 정확도]** : 출력결과가 **얼마나 TRUE에 가까운지**를 나타냄. **참값과의 차이**\n",
    "- **[Precision 정밀도]** : 시스템이 **얼마나 일관된 값을 출력하는지**를 나타냄. **반복에 따른 차이**\n",
    "\n",
    "- 구분 예\n",
    "    - 5분 느린 시계가 있는데 1시간 뒤에도, 1일 뒤에도, 10년 뒤에도 동일하게 5분 느리다면 그 시계는 정밀하지만 정확하지 않다.\n",
    "    - 기상 예보가 실제 기상과 맞았다면 정확한 예보다.\n",
    "    - 같은 기상 자료를 어제, 오늘, 내일 분석해서 같은 결과가 나오면 정밀한 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8_2. [ROC Curve Receiver-Operating Characteristic Curve 수신자 조작 특성 곡선] \n",
    "\n",
    "수신자 조작특성, 반응자 작용특성, 수용자 반응특성은 **[TPR True Positive Rate = Sensitivity 적중확률] 대 [FPR False Positive Rate 오경보확률]**의 그래프이다. ROC 곡선은 정기각률이 늘어나면 탈루률이 늘어나느 관계를 효용 대 비용의 관계로 설명한다.\n",
    "\n",
    "- ROC는 레이더 이미지 분석의 성과를 측정하기 위해 개발됨\n",
    "- 분류의 목적변수를 얼마나 잘 찾아주는지를 나타내는 평가 모형\n",
    "- 좌상에 가까울 수록 좋은 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/ROC_curves.svg/300px-ROC_curves.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity & Sensitivity\n",
    "\n",
    "- ROC의 AUC 구하기 : http://adnoctum.tistory.com/121\n",
    "\n",
    "ROC는 민감도와 특이도가 어떤 관계인지 표현한 그래프이다. **[Sensitivity 민감도]**는 진짜 환자 중에서 환자를 얼마나 잘 골라내는가이고, **[Specificity 특이도]** 정상인 중에서 정상인을 얼마나 잘 골라내는가를 의미한다. \n",
    "\n",
    "- 심근경색 예\n",
    "    - 만일 혈압이 5이상이면 심근경색이라고 하면 모든 사람이 심근경색 환자로 판별되어 누구나 환자로 판정된다.\n",
    "    - 따라서 100%로 환자를 진단할 수 있지만 환자가 아닌 사람도 몽땅 환자가 되어 특이도가 0이 되어 버린다.\n",
    "    - 반대로 혈압이 1000 이상이면 심근경색이다라고 하면 모든 사람이 정상으로 판정되어 특이도는 100%가 되지만 민감도는 0이 된다.\n",
    "    - 모든 분류 방법은 민감도와 특이도를 같이 고려해야 하며, 적당한 민감도와 특이도는 0.8~0.9 사이이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [AUC Area Under the Curve]\n",
    "\n",
    "- [MedCalc] ROC 곡선(ROC Curve) : https://blog.naver.com/y4769/220290362114\n",
    "- Understanding AUC - ROC Curve : https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
    "\n",
    "AUC는 곡선 아래 면적이란 의미로 ROC 커브의 밑면적을 계산한 값이다. 2005년 Muller는 AUC 등급을 1~0.9는 Excellent, 0.9~0.8은 Good, 0.6~0.5는 Fail 등으로 표기하였다.\n",
    "\n",
    "- 값이 1에 가까울 수록 이상적.\n",
    "- 절대값이 아닌 예측이 얼마나 잘 평가되는지 측정하는 척도 불변의 성질\n",
    "- 어떤 분류 임계값이 선택되었느지 상관없이 모델의 예측 품질을 측정\n",
    "\n",
    "\n",
    "- 예측과 실제가 완벽하게 일치하는 상태\n",
    "![img](https://cdn-images-1.medium.com/max/1600/1*Uu-t4pOotRQFoyrfqEvIEg.png)\n",
    "\n",
    "- 일반적인 분류 상태 \n",
    "![img](https://cdn-images-1.medium.com/max/1600/1*yF8hvKR9eNfqqej2JnVKzg.png)\n",
    "\n",
    "- 최악의 상태, 분류가 하나도 안 된 상태\n",
    "![img](https://cdn-images-1.medium.com/max/1600/1*iLW_BrJZRI0UZSflfMrmZQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공신경망 Iris 예제 : http://localhost:8888/notebooks/%5Bdata%5D%20NNet_iris_ROC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
