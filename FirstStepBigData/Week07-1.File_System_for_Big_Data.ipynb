{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1. File System for Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic1. Combiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. HDFS - Block based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-1. MapReduce Phase\n",
    "앞에서 살펴본 것 외에 Combine 기능을 알아본다. 단어 빈도 계산 예제에서 Map 부분에서 각 청크별 단어의 개수를 세고, Reduce 부분에서 결과를 병합하는 기능을 하였다.\n",
    "- 그럼 한 청크에서 동일한 작업이 연속해서 일어날 경우는?\n",
    "- (w1,1)이 2번 일어났다면 (w1,2)식으로 보내는 것이 더 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1-2. Combiner\n",
    "한 작업안에서 같은 키가 나올 경우 병합하는 작업을 의미한다.\n",
    "- 실질적으로 **reduce 함수와 동일**\n",
    "- 단지 conbiner는 하나의 output에 대해서만 작동\n",
    "- reduce는 모든 output에 대해서 작동\n",
    "\n",
    "- Combin function\n",
    "``` c\n",
    "combine(String intermedia_key, Iterator intermediate_values):\n",
    "    // output_key : word\n",
    "    // output_value : ????\n",
    "    int result = 0;\n",
    "    for each v in intermediate_values:\n",
    "        result += v;\n",
    "       Emit(intermediate_key, result);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 2. Cluster Computing for Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Cluster Computing for Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-1. Taxonomy\n",
    "\n",
    "- shared memory : 과거의 병렬처리 방식. CPU를이 공통의 메모리를 사용. 메모리 관리 중요. \n",
    "- shared disk : CPU가 각각의 메모리를 가지고 disk를 공유해서 사용 \n",
    "- shared nothing : 각각의 머신이 독립된 CPU, 메모리, 디스크를 가짐, 맵 리듀스에 주로 사용.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1-2. Cluster Computing\n",
    "\n",
    "네트워크로 연결된 많은 수의 서버를 의미한다.\n",
    "- **Rack** : 20~40대 정도의 적은 수의 서버\n",
    "- **Data Center** : 많은 수의 랙\n",
    "- **Massive Paralleism** : 많은 컴퓨터를 오랜 시간 사용시 문제 발생\n",
    "- **Failure** : 하드디스크를 장시간 사용시 문제 발생(Medium-time-between-failure). 대략 만대의 서버가 1시간에 1번 정도 오류 발생."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 3. File System for Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. File System for Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1-1. Distributed File System (DFS)\n",
    "초당 TB, PB등 대용량 데이터를 다루는데 파일이 너무 클 경우 한번의 디스크에 들어갈 수 없을 경우 분산하여 사용해야 한다.\n",
    "- **DFS** : 수많은 디스크를 하나로 사용할 수 있게 해주는 시스템\n",
    "- **GFS** : 구글의 DFS\n",
    "- **HDFS** : 하둡의 HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. HDFS - Black Based\n",
    "우선 큰 파일을 기본적으로 64MB 나누어 각각의 노드로 분리한다. 각각의 분리된 객체에서는 3개의 블럭으로 나누어 관리한다.\n",
    "- 64MB의 Unit / 3 Blocck의 레플리카\n",
    "- 하나의 하드가 고장나도 데이터를 유지할 수 있게 분산 복제 저장\n",
    "\n",
    "![HDFS](./img/07-1-001-HDFS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4. Parallel / Distributed Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Parallel / Distributed Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-1. Large-Scale Data Processing\n",
    "\n",
    "과거에도 큰 데이터를 처리하기 위한 시도들중 병렬 데이터베이스가 있었다.\n",
    "- 단점 : 비싼 가격, 유지보수 어려움, 100대 이상 설치 어려움\n",
    "- **MapReduce의 장점** : 자동 병렬 및 분산 처리, 오류 방지, 입출력 계획, 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-2. Two Notions Parallel Query Processing\n",
    "과거에는 크게 2가지 경우로 처리하였다.\n",
    "- **Distributed Query** : 쿼리를 나누어 처리하는 방식\n",
    "- **Parallel Query** : **해쉬**알고리즘(히든영역)에서 나누어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-3. Key Idea\n",
    "쿼리 예시를 통해 어떻게 작동하는지 알아보자.\n",
    "\n",
    "```mysql\n",
    "SELECT *\n",
    "FROM Order o, Item i\n",
    "WHERE o.orID = i.orId\n",
    "AND o.date = today()\n",
    "```\n",
    "\n",
    "1. join : 우선 조인 과정이 이루어짐\n",
    "1. select : 날짜가 오늘인지 조회\n",
    "1. scan : 데이터를 스켄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-4. Parallel Data Processing\n",
    "위 쿼리가 병렬 처리 방식에서 실행되는 방식이다.\n",
    "- 분산 노드 : 여러개의 노드로 분산저장, 어느 노드에 저장되었는지 알 수 없다.\n",
    "- select : 각 노드에서 date가 오늘인 것을 조회, 해쉬기능 사용\n",
    "- scan : 조건에 부합하는 데이터를 스캔\n",
    "- 이런 과정이 **Shuffling**과 **Reduce** 기능과 유사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
