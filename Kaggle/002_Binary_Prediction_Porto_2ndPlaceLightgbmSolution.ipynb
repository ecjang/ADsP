{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porto Kernel : https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/kernels\n",
    "- 2nd Place Lightgbm Solution : https://www.kaggle.com/xiaozhouwang/2nd-place-lightgbm-solution\n",
    "- 포트투 커널 스터디 5 : https://www.youtube.com/watch?v=mZSh9_Lh_5g&list=PLC_wC_PMBL5NLKkMooi-n4iK4gv3VqXyo&index=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Place Lightgbm Solution\n",
    "\n",
    "Part of 2nd Place soultion : Lightgbm model with private score 0.29124 and public 1b socre 0.28555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [import Library](#001)\n",
    "1. [Define Gini](#002)\n",
    "1. [Define Global Variables](#003)\n",
    "1. [Define Evalerror](#004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"001\"></a>\n",
    "\n",
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jang/.pyenv/versions/3.6.5/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='002'></a>\n",
    "\n",
    "## Define Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_ture, y_pred):\n",
    "    \n",
    "    # Check and get number of sample\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column\n",
    "    # from largest to smallest\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "    \n",
    "    #get Lorenz curves\n",
    "    L_ture = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_sample, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"003\"></a>\n",
    "\n",
    "## Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_only = True\n",
    "save_cv = True\n",
    "full_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"004\"></a>\n",
    "\n",
    "## Define Evalerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    lavels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"005\"></a>\n",
    "\n",
    "## Setting Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../input/porto/\"\n",
    "train = pd.read_csv(path+'train.csv', na_values=-1, nrows=10000)\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "test = pd.read_csv(path+'test.csv', na_values=-1, nrows=10000)\n",
    "test_id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2            2.0          5            1.0   \n",
       "1   9       0          1            1.0          7            0.0   \n",
       "2  13       0          5            4.0          9            1.0   \n",
       "3  16       0          0            1.0          2            0.0   \n",
       "4  17       0          0            2.0          0            1.0   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0            0.0              0              1              0       ...         \n",
       "1            0.0              0              0              1       ...         \n",
       "2            0.0              0              0              1       ...         \n",
       "3            0.0              1              0              0       ...         \n",
       "4            0.0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=218, shuffle=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인 결과 대부분의 값은 0이다.\n",
    "y = train['target'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature = ['id', 'target']\n",
    "X = train.drop(drop_feature, axis=1)\n",
    "feature_names = X.columns.tolist()\n",
    "cat_feature = [c for c in feature_names if ('cat' in c and 'count' not in c)]\n",
    "num_feature = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat']\n"
     ]
    }
   ],
   "source": [
    "# 확인결과 카테고리 변수들은 아래와 같다. 총 14개가 있다.\n",
    "cat_feature = [c for c in feature_names if ('cat' in c and 'count' not in c)]\n",
    "print(len(cat_feature))\n",
    "print(cat_feature[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([c for c in feature_names if ('cat' in c and 'count' not in c)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = train['target'].values\n",
    "drop_feature = [\n",
    "    'id',\n",
    "    'target'\n",
    "]\n",
    "\n",
    "X = train.drop(drop_feature,axis=1)\n",
    "feature_names = X.columns.tolist()\n",
    "cat_features = [c for c in feature_names if ('cat' in c and 'count' not in c)]\n",
    "num_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]\n",
    "\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "num_features.append('missing')\n",
    "\n",
    "for c in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[c])\n",
    "    train[c] = le.transform(train[c])\n",
    "    test[c] = le.transform(test[c])\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train[cat_features])\n",
    "X_cat = enc.transform(train[cat_features])\n",
    "X_t_cat = enc.transform(test[cat_features])\n",
    "\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count=0\n",
    "for c in ind_features:\n",
    "    if count==0:\n",
    "        train['new_ind'] = train[c].astype(str)+'_'\n",
    "        test['new_ind'] = test[c].astype(str)+'_'\n",
    "        count+=1\n",
    "    else:\n",
    "        train['new_ind'] += train[c].astype(str)+'_'\n",
    "        test['new_ind'] += test[c].astype(str)+'_'\n",
    "\n",
    "cat_count_features = []\n",
    "for c in cat_features+['new_ind']:\n",
    "    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n",
    "    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)\n",
    "\n",
    "train_list = [train[num_features+cat_count_features].values,X_cat,]\n",
    "test_list = [test[num_features+cat_count_features].values,X_t_cat,]\n",
    "\n",
    "X = ssp.hstack(train_list).tocsr()\n",
    "X_test = ssp.hstack(test_list).tocsr()\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.6\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "\n",
    "x_score = []\n",
    "final_cv_train = np.zeros(len(train_label))\n",
    "final_cv_pred = np.zeros(len(test_id))\n",
    "for s in xrange(16):\n",
    "    cv_train = np.zeros(len(train_label))\n",
    "    cv_pred = np.zeros(len(test_id))\n",
    "\n",
    "    params['seed'] = s\n",
    "\n",
    "    if cv_only:\n",
    "        kf = kfold.split(X, train_label)\n",
    "\n",
    "        best_trees = []\n",
    "        fold_scores = []\n",
    "\n",
    "        for i, (train_fold, validate) in enumerate(kf):\n",
    "            X_train, X_validate, label_train, label_validate = \\\n",
    "                X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n",
    "            dtrain = lgbm.Dataset(X_train, label_train)\n",
    "            dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "            bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                            early_stopping_rounds=100)\n",
    "            best_trees.append(bst.best_iteration)\n",
    "            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "            cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "            score = Gini(label_validate, cv_train[validate])\n",
    "            print score\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        cv_pred /= NFOLDS\n",
    "        final_cv_train += cv_train\n",
    "        final_cv_pred += cv_pred\n",
    "\n",
    "        print(\"cv score:\")\n",
    "        print Gini(train_label, cv_train)\n",
    "        print \"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1\n",
    "        print(fold_scores)\n",
    "        print(best_trees, np.mean(best_trees))\n",
    "\n",
    "        x_score.append(Gini(train_label, cv_train))\n",
    "\n",
    "print(x_score)\n",
    "pd.DataFrame({'id': test_id, 'target': final_cv_pred / 16.}).to_csv('../model/lgbm3_pred_avg.csv', index=False)\n",
    "pd.DataFrame({'id': train_id, 'target': final_cv_train / 16.}).to_csv('../model/lgbm3_cv_avg.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
